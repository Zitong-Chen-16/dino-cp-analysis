{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../profiling/\")\n",
    "import profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"well_level_profiles_vits_LINCS_1e-5_final.csv\"\n",
    "REG_PARAM = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "meta = pd.read_csv(\"/scr/data/LINCS/DP-project/outputs/max_concentration_set/sc-metadata.csv\")\n",
    "meta_add = pd.read_csv(\"/scr/data/LINCS/DP-project/outputs/SQ00015147_maxconc/sc-metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [str(f) for f in Path('/scr/zitong/cp_dino/experiments/DINO01/LINCS/').glob('features*.pth')]\n",
    "open_files = [torch.load(f) for f in files]\n",
    "features = torch.concat([f[0] for f in open_files])\n",
    "\n",
    "print(\"Total images:\",features.shape[0])\n",
    "print(\"Number of features per image:\", features.shape[1])\n",
    "\n",
    "# cell_names = np.concatenate(([f[1] for f in open_files]))\n",
    "# torch.save((features, cell_names), '/scr/zitong/cp_dino/experiments/DINOBASE/Combined/features.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_add = [str(f) for f in Path('/scr/zitong/cp_dino/experiments/DINO01/LINCS/additional/').glob('features*.pth')]\n",
    "open_files_add = [torch.load(f) for f in files_add]\n",
    "features_add = torch.concat([f[0] for f in open_files_add])\n",
    "\n",
    "print(\"Total images:\",features_add.shape[0])\n",
    "print(\"Number of features per image:\", features_add.shape[1])\n",
    "\n",
    "# cell_names = np.concatenate(([f[1] for f in open_files]))\n",
    "# torch.save((features, cell_names), '/scr/zitong/cp_dino/experiments/DINOBASE/Combined/features.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = StandardScaler().fit_transform(features.numpy())\n",
    "scaled_features_add = StandardScaler().fit_transform(features_add.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = np.concatenate(([f[1] for f in open_files]))\n",
    "order, ordered_features = (np.array(t) for t in zip(*sorted(zip(cell_names, scaled_features))))\n",
    "\n",
    "cell_names_add = np.concatenate(([f[1] for f in open_files_add]))\n",
    "order_add, ordered_features_add = (np.array(t) for t in zip(*sorted(zip(cell_names_add, scaled_features_add))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Site-level profiles / Median Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict = meta.groupby('Key').groups\n",
    "print(\"Grouping finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_level_data = []\n",
    "site_level_features = []\n",
    "\n",
    "for site_name in tqdm(list(group_dict.keys())):\n",
    "    metadata = site_name.split('/')\n",
    "    if metadata[0] == 'SQ00015147': continue\n",
    "    indices = group_dict[site_name]\n",
    "    mean_profile = np.median(ordered_features[indices], axis=0)\n",
    "    \n",
    "    site_level_data.append(\n",
    "        {\n",
    "            \"Plate\": metadata[0],\n",
    "            \"Well\": metadata[1],\n",
    "            \"Treatment\": meta[\"Treatment\"][indices].unique()[0]\n",
    "        }\n",
    "\n",
    "    )\n",
    "    site_level_features.append(mean_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_dict = meta_add.groupby(['Key']).groups\n",
    "for site_name in tqdm(list(site_dict.keys())):\n",
    "    metadata = site_name.split('/')\n",
    "    indices = site_dict[site_name]\n",
    "    mean_profile = np.median(ordered_features_add[indices], axis=0)\n",
    "    \n",
    "    site_level_data.append(\n",
    "        {\n",
    "            \"Plate\": metadata[0],\n",
    "            \"Well\": metadata[1],\n",
    "            \"Treatment\": meta_add[\"Treatment\"][indices].unique()[0]\n",
    "        }\n",
    "\n",
    "    )\n",
    "    site_level_features.append(mean_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 384\n",
    "columns1 = [\"Plate\", \"Well\", \"Treatment\"] # dataset\n",
    "columns2 = [i for i in range(num_features)]\n",
    "\n",
    "sites1 = pd.DataFrame(columns=columns1, data=site_level_data)\n",
    "sites2 = pd.DataFrame(columns=columns2, data=site_level_features)\n",
    "sites = pd.concat([sites1, sites2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites[\"Treatment_Clean\"] = sites[\"Treatment\"].apply(lambda x: \"-\".join([str(i) for i in x.split(\"-\")[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Well-level profiles / Mean Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse well data\n",
    "wells = sites.groupby([\"Plate\", \"Well\", \"Treatment\", \"Treatment_Clean\"]).mean().reset_index()\n",
    "wells[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells.to_csv(\"Wells_Prewhitened_ViT_small_LINCS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(wells[\"Treatment\"].isin([\"DMSO@NA\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "whN = profiling.WhiteningNormalizer(wells.loc[wells[\"Treatment\"].isin([\"DMSO@NA\"]), columns2], REG_PARAM)\n",
    "whD = whN.normalize(wells[columns2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save whitened profiles\n",
    "wells[columns2] = whD\n",
    "wells.to_csv(OUTPUT_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CP_DINO",
   "language": "python",
   "name": "cp_dino"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
